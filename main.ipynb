{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, Input\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = [\n",
    "    'ambulance',\n",
    "    'army vehicle',\n",
    "    'auto rickshaw',\n",
    "    'bicycle',\n",
    "    'bus',\n",
    "    'car',\n",
    "    'garbagevan',\n",
    "    'human hauler',\n",
    "    'minibus',\n",
    "    'minivan',\n",
    "    'motorbike',\n",
    "    'pickup',\n",
    "    'policecar',\n",
    "    'rickshaw',\n",
    "    'scooter',\n",
    "    'suv',\n",
    "    'taxi',\n",
    "    'three wheelers -CNG-',\n",
    "    'truck',\n",
    "    'van',\n",
    "    'wheelbarrow'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, upto=np.inf):\n",
    "    \n",
    "    images = []\n",
    "    annotations = []\n",
    "    i = 0\n",
    "\n",
    "    images_dir = os.path.join(data_dir, 'train', 'images')\n",
    "    labels_dir = os.path.join(data_dir, 'train', 'labels')\n",
    "\n",
    "    for filename in os.listdir(images_dir):\n",
    "        if i == upto:\n",
    "            break\n",
    "        if filename.endswith('.jpg'):\n",
    "            img_path = os.path.join(images_dir, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            images.append(img)\n",
    "\n",
    "            label_path = os.path.join(labels_dir, filename.replace('.jpg', '.txt'))\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                boxes = []\n",
    "                classes = []\n",
    "                for line in lines:\n",
    "                    values = line.strip().split()\n",
    "                    class_id = int(values[0])\n",
    "                    x, y, w, h = map(float, values[1:])\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    classes.append(class_id)\n",
    "                annotations.append({'boxes': boxes, 'classes': classes})\n",
    "        \n",
    "        i += 1\n",
    "        print(f'For iter {i} collected image: {filename}')\n",
    "\n",
    "    return np.array(images), annotations\n",
    "\n",
    "def object_outline(image, annotation, names=False):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    for i, box in enumerate(annotation['boxes']):\n",
    "        x_center, y_center, width, height = box\n",
    "        \n",
    "        x_min = int((x_center - width / 2) * image.shape[1])\n",
    "        y_min = int((y_center - height / 2) * image.shape[0])\n",
    "        x_max = int((x_center + width / 2) * image.shape[1])\n",
    "        y_max = int((y_center + height / 2) * image.shape[0])\n",
    "        \n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        if names:\n",
    "            ax.text(x_min, y_min, objects[annotation['classes'][i]], fontsize=12, color='r')\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def prepare_data(annotations):\n",
    "    y_class = []\n",
    "    y_bbox = []\n",
    "\n",
    "    for annotation in annotations:\n",
    "        classes = annotation['classes']\n",
    "        boxes = annotation['boxes']\n",
    "        \n",
    "        y_class.append(classes)\n",
    "        y_bbox.append(boxes)\n",
    "\n",
    "    return np.array(y_bbox), np.array(y_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For iter 1 collected image: 01_jpg.rf.8d8a2f0f90d5b83893cd252acd832c93.jpg\n",
      "For iter 2 collected image: 02_jpg.rf.65a084066fc353cd023eb5c953f40efe.jpg\n",
      "For iter 3 collected image: 03_jpg.rf.4532f2db68433995da09f54e215160f3.jpg\n",
      "For iter 4 collected image: 04_jpg.rf.c0b83432c4d09c7cbeaac18e14c4a54a.jpg\n",
      "For iter 5 collected image: 05_jpg.rf.11a2e7ce391a1e74960099f7923f27f5.jpg\n",
      "For iter 6 collected image: 06_jpeg.rf.14bdc2005d8029bbe9f24fad4b6af7ea.jpg\n",
      "For iter 7 collected image: 07_jpg.rf.8447b11632c1b63ab0e127f16625e0d2.jpg\n",
      "For iter 8 collected image: 08_jpg.rf.837e69c4e93e62472911c1d18be143a4.jpg\n",
      "For iter 9 collected image: 09_jpg.rf.42406b1c067f04bf73349bd75b2e3fa8.jpg\n",
      "For iter 10 collected image: 100_jpg.rf.971dbb99e07828d1655d69bbfb7136be.jpg\n",
      "For iter 11 collected image: 101_jpg.rf.2737e79396d350c7eeb5bf867c346077.jpg\n",
      "For iter 12 collected image: 102_jpg.rf.2d884248dcc60b7d6b93f61df77921df.jpg\n",
      "For iter 13 collected image: 103_jpg.rf.cb820e037e0ccc6163377e9ead1fea10.jpg\n",
      "For iter 14 collected image: 104_jpg.rf.69544ebdaf59239e1d742da7bde4afb4.jpg\n",
      "For iter 15 collected image: 105_jpg.rf.cbfae4b633dff2527e3514746c223f05.jpg\n",
      "For iter 16 collected image: 106_jpg.rf.256148b75cf465e3e6f69d7c092fe9d9.jpg\n",
      "For iter 17 collected image: 107_jpg.rf.18145cfc61bb4fb65a51b7be59dda81a.jpg\n",
      "For iter 18 collected image: 108_jpg.rf.b5a13c05d20239a99424b5a579db8242.jpg\n",
      "For iter 19 collected image: 109_jpg.rf.ff9fc798c246110361741e5713844cdd.jpg\n",
      "For iter 20 collected image: 10_jpg.rf.2909dc493f5192456a4d7a2cc8735ce5.jpg\n"
     ]
    }
   ],
   "source": [
    "images, annotations = load_data('trafic_data', 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
